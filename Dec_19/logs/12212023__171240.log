[2023-12-21 17:12:43,654 ] 15 root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Data Ingestion <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[2023-12-21 17:12:43,654 ] 22 root - INFO - Exporting collection data as dataframe
[2023-12-21 17:12:43,654 ] 22 root - INFO - Reading dataframe from mongodb database aps and collection sensor
[2023-12-21 17:13:24,812 ] 24 root - INFO - Found columns Index(['_id', 'class', 'aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000',
       'af_000', 'ag_000', 'ag_001',
       ...
       'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008',
       'ee_009', 'ef_000', 'eg_000'],
      dtype='object', length=172)
[2023-12-21 17:13:25,069 ] 27 root - INFO - Rows and columns in df:(36188, 171)
[2023-12-21 17:13:26,218 ] 31 root - INFO - Creating feature store folder if not available
[2023-12-21 17:13:26,218 ] 35 root - INFO - Save df to feature store folder
[2023-12-21 17:13:28,280 ] 39 root - INFO - split the dataset into train and test dataset
[2023-12-21 17:13:28,514 ] 43 root - INFO - Creating dataset directory folder if not available
[2023-12-21 17:13:28,514 ] 48 root - INFO - Save df to dataset folder
[2023-12-21 17:13:30,402 ] 60 root - INFO - Data Ingestion Artifact:DataIngestionArtifact(feature_store_file_path='C:\\Users\\Prince\\Desktop\\Practice\\iNeuron\\Dec_19\\artifact\\21122023__171243\\data ingestion\\feature_store\\sensor.csv', train_file_path='C:\\Users\\Prince\\Desktop\\Practice\\iNeuron\\Dec_19\\artifact\\21122023__171243\\data ingestion\\dataset\\train.csv', test_file_path='C:\\Users\\Prince\\Desktop\\Practice\\iNeuron\\Dec_19\\artifact\\21122023__171243\\data ingestion\\dataset\\test.csv')
[2023-12-21 17:13:30,810 ] 18 root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Data Valiation <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[2023-12-21 17:13:30,810 ] 101 root - INFO - Reading base dataframe
[2023-12-21 17:13:33,630 ] 104 root - INFO - Replacing na value in base_df
[2023-12-21 17:13:33,630 ] 107 root - INFO - Dropping null values from base_df
[2023-12-21 17:13:33,874 ] 38 root - INFO - selecting column name which contains null values above to 0.2
[2023-12-21 17:13:33,874 ] 41 root - INFO - Columns to drop: ['ab_000', 'ad_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'cf_000', 'cg_000', 'ch_000', 'co_000', 'cr_000', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000'] 
[2023-12-21 17:13:33,996 ] 110 root - INFO - Reading train dataframe
[2023-12-21 17:13:34,715 ] 112 root - INFO - Reading test dataset
[2023-12-21 17:13:34,907 ] 115 root - INFO - Dropping null value columns from train and test dataset
[2023-12-21 17:13:34,922 ] 38 root - INFO - selecting column name which contains null values above to 0.2
[2023-12-21 17:13:34,922 ] 41 root - INFO - Columns to drop: ['ab_000', 'ad_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'cf_000', 'cg_000', 'ch_000', 'co_000', 'cr_000', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000'] 
[2023-12-21 17:13:34,969 ] 38 root - INFO - selecting column name which contains null values above to 0.2
[2023-12-21 17:13:34,970 ] 41 root - INFO - Columns to drop: ['ab_000', 'ad_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'cf_000', 'cg_000', 'ch_000', 'co_000', 'cr_000', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000'] 
[2023-12-21 17:13:34,977 ] 120 root - INFO - converted features to float
[2023-12-21 17:13:36,456 ] 125 root - INFO - Is all required column present in train df
[2023-12-21 17:13:36,456 ] 127 root - INFO - Is all required column present in test df
[2023-12-21 17:13:36,456 ] 131 root - INFO - As all columns are available in train df hence detecting data drift
[2023-12-21 17:13:38,883 ] 134 root - INFO - As all columns are available in test df hence detecting data drift
[2023-12-21 17:13:40,013 ] 138 root - INFO - writing report in yaml file
[2023-12-21 17:13:40,054 ] 143 root - INFO - Data Validation artifact:DataValidationArtifact(report_file_path='C:\\Users\\Prince\\Desktop\\Practice\\iNeuron\\Dec_19\\artifact\\21122023__171243\\data_validation\\report.yaml')
[2023-12-21 17:13:40,127 ] 21 root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Data Transformation <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[2023-12-21 17:13:40,127 ] 45 root - INFO - Reading train and test df
[2023-12-21 17:13:41,059 ] 48 root - INFO - Successfully read the dataset
[2023-12-21 17:13:41,729 ] 73 root - INFO - Before resampling in training dataset: Input features(28950, 170) Target:(28950,) 
[2023-12-21 17:14:11,403 ] 75 root - INFO - Before resampling in testing dataset: Input features(7238, 170) Target:(7238,) 
[2023-12-21 17:14:13,588 ] 68 root - INFO - Entered the save object method of utils
[2023-12-21 17:14:13,620 ] 72 root - INFO - Pipeline(steps=[('Imputer', SimpleImputer(fill_value=0, strategy='constant')),
                ('RobustScaler', RobustScaler())]) Object has been successfully saved and exiting now
[2023-12-21 17:14:13,620 ] 68 root - INFO - Entered the save object method of utils
[2023-12-21 17:14:13,625 ] 72 root - INFO - LabelEncoder() Object has been successfully saved and exiting now
[2023-12-21 17:14:13,661 ] 16 root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Model Trainer <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[2023-12-21 17:14:13,662 ] 33 root - INFO - Loading train and test array
[2023-12-21 17:14:13,748 ] 37 root - INFO - Splitting input and target feature from both train and test array
